# ğŸ“š TalkBookAI

**TalkBookAI** lets readers *chat with books*â€”literally. Log in, pick a book from the list, and start a conversation with an AI that responds in the voice of the author, drawing from the bookâ€™s content and your ongoing chat history. Itâ€™s like having a personal dialogue with literary legends.

---

## ğŸ§  Tech Stack

### Backend (`/backend`)

- **FastAPI** â€“ blazing-fast Python API framework  
- **MongoDB Atlas** â€“ document storage + vector search  
- **LangChain** â€“ orchestrates RAG (Retrieval-Augmented Generation) pipelines  
- **Gemini API** â€“ powers LLM responses and embeddings  
- **JWT Auth** â€“ secure session management with HTTP-only cookies  
- **Docker + Render** â€“ containerized deployment  

### Frontend (`/frontend`)

- **React Router v7 (Framework Mode)** â€“ SPA routing & nested layouts  
- **Tailwind CSS + ShadCN UI** â€“ modern styling and accessible components  
- **Vercel** â€“ lightning-fast global deployment  

---

## âœ¨ Features

- ğŸ” **Authentication** â€“ JWT stored in HTTP-only cookies  
- ğŸ“– **Book Selection** â€“ choose from a curated library  
- ğŸ§‘â€ğŸ’¬ **Conversational AI** â€“ responds in the *voice* of the author  
- ğŸ§  **Memory** â€“ contextual replies based on previous chat turns  
- ğŸ“„ **PDF Ingestion** â€“ onboard new books with an ingestion script  
- ğŸŒ **CORS-Enabled** â€“ secure frontend-backend communication  

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.11+  
- Node.js 22+  
- Docker *(optional, for containerized setup)*  
- MongoDB Atlas account  
- Gemini API key  

---

### Backend Setup

```bash
cd backend
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt

# .env file variables:
# MONGODB_URI=
# GOOGLE_API_KEY=
# SECRET_KEY=
# DB_NAME=
# FRONTEND_URL=

fastapi dev
````

#### (Optional) Docker Workflow

```bash
cd backend
docker build -t talkbookai-backend .
docker run -p 8000:8000 --env-file .env talkbookai-backend
```

> Uses a minimal **python:3.11-slim** base and launches `uvicorn main:app --host 0.0.0.0 --port 8000`.

---

### Frontend Setup

```bash
cd frontend
npm install

# .env file variables:
# VITE_BACKENDURL=

npm run dev
```

---

## ğŸ§ª PDF Ingestion

To ingest a new book:

```bash
cd backend
python ingestion_handler.py   # or: py -m ingestion_handler
```

The script:

- Extracts and chunks the text
- Generates embeddings via **Gemini**
- Stores metadata and vectors in **MongoDB**

---

## ğŸ›¡ï¸ Security Notes

- JWTs are stored in **HTTP-only cookies** to mitigate XSS attacks
- CORS configured for safe cross-origin requests (Vercel â†” Render)
- Secrets managed in `.env` files (never committed to version control)

---

## Screenshot

![Talkbook Screenshot](frontend/public/talkbookai.png)

---

## ğŸ“ˆ Roadmap

- [ ] Chapter-specific context retrieval
- [ ] Multi-author personality modes

---

## ğŸ“„ License

MIT License
